# å¸¦ç¼ºæ‹¼éŸ³æŸ¥æ±‰å­—åŠŸèƒ½
# åŸºäºæ–°åå­—å…¸æ•°æ®ï¼Œæ”¯æŒé€šè¿‡ç¬”ç”»æ•°ã€å£°æ¯ã€éŸµæ¯ç­‰æ¡ä»¶æŸ¥è¯¢æ±‰å­—

import json
import re
import os
from typing import List, Dict, Optional, Set, Tuple


class PinyinSearcher:
    """æ‹¼éŸ³æŸ¥æ±‰å­—å·¥å…·ç±»"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ‹¼éŸ³æŸ¥æ±‰å­—å·¥å…·"""
        self.words_data = []
        self.initials = set()  # å£°æ¯é›†åˆ
        self.finals = set()    # éŸµæ¯é›†åˆ
        self.tones = set()     # éŸ³è°ƒé›†åˆ
        self._load_data()
        
    def _load_data(self):
        """åŠ è½½æ–°åå­—å…¸æ•°æ®"""
        # è·å–æ•°æ®æ–‡ä»¶è·¯å¾„ï¼Œä¼˜å…ˆä½¿ç”¨åŒ…å«ç¬”é¡ºä¿¡æ¯çš„æ–°è¯å…¸
        current_dir = os.path.dirname(os.path.abspath(__file__))
        data_file = os.path.join(current_dir, "word-new.json")        
        try:
            with open(data_file, 'r', encoding='utf-8') as f:
                self.words_data = json.load(f)
            # å¤„ç†å¤šéŸ³å­—æ•°æ®
            self._process_multiple_pronunciations()
            self._analyze_pinyin_components()
            
            # æ£€æŸ¥æ˜¯å¦åŠ è½½äº†åŒ…å«ç¬”é¡ºä¿¡æ¯çš„æ•°æ®
            has_stroke_order = any(word.get('order') is not None for word in self.words_data[:10])
            stroke_info = "ï¼ˆåŒ…å«ç¬”é¡ºä¿¡æ¯ï¼‰" if has_stroke_order else "ï¼ˆä¸å«ç¬”é¡ºä¿¡æ¯ï¼‰"
            
            print(f"æˆåŠŸåŠ è½½ {len(self.words_data)} ä¸ªæ±‰å­—æ•°æ® {stroke_info}")
        except FileNotFoundError:
            print(f"è­¦å‘Šï¼šæ‰¾ä¸åˆ°å­—å…¸æ–‡ä»¶ {data_file}")
            self.words_data = []
        except Exception as e:
            print(f"åŠ è½½å­—å…¸æ•°æ®æ—¶å‡ºé”™ï¼š{e}")
            self.words_data = []
    
    def _process_multiple_pronunciations(self):
        """å¤„ç†å¤šéŸ³å­—æ•°æ®ï¼Œä»moreå­—æ®µä¸­æå–é¢å¤–çš„è¯»éŸ³"""
        for word_info in self.words_data:
            word = word_info.get('word', '')
            more = word_info.get('more', '')
            base_pinyin = word_info.get('pinyin', '')
            
            # æ”¶é›†æ‰€æœ‰è¯»éŸ³ï¼Œä»¥åˆ—è¡¨å½¢å¼å­˜å‚¨
            all_pronunciations = []
            if base_pinyin:
                all_pronunciations.append(base_pinyin)
            
            if more and word:
                # åœ¨moreå­—æ®µä¸­æŸ¥æ‰¾æ ¼å¼å¦‚"å­—1"ã€"å­—2"ç­‰çš„å¤šéŸ³å­—æ ‡è®°
                pronunciations = self._extract_pronunciations_from_more(word, more)
                all_pronunciations.extend(pronunciations)
            
            # å»é‡å¹¶æ›´æ–°æ‹¼éŸ³å­—æ®µä¸ºåˆ—è¡¨
            word_info['pinyin_list'] = list(set(all_pronunciations)) if all_pronunciations else [base_pinyin] if base_pinyin else []
    
    def _extract_pronunciations_from_more(self, word: str, more: str) -> List[str]:
        """ä»moreå­—æ®µä¸­æå–å¤šéŸ³å­—çš„è¯»éŸ³"""
        pronunciations = []
        
        # æŸ¥æ‰¾æ ¼å¼å¦‚"å­—1\nè¯»éŸ³"ã€"å­—2\nè¯»éŸ³"çš„æ¨¡å¼
        pattern = re.compile(rf'{re.escape(word)}(\d+)\n([^\n\s]+)', re.MULTILINE)
        matches = pattern.findall(more)
        
        for match in matches:
            pronunciation = match[1].strip()
            if pronunciation:
                pronunciations.append(pronunciation)
        
        return pronunciations
    
    def _analyze_pinyin_components(self):
        """åˆ†ææ‹¼éŸ³æ•°æ®ï¼Œæå–å£°æ¯ã€éŸµæ¯ã€éŸ³è°ƒ"""
        # æ ‡å‡†å£°æ¯åˆ—è¡¨ï¼ˆå›ºå®šï¼‰
        standard_initials = {
            'b', 'p', 'm', 'f', 'z', 'c', 's', 'd', 't', 'n', 'l', 
            'zh', 'ch', 'sh', 'r', 'j', 'q', 'x', 'h', 'k', 'g', 'y', 'w'
        }
        
        # æ ‡å‡†éŸµæ¯åˆ—è¡¨ï¼ˆå›ºå®šï¼‰
        standard_finals = {
            'a', 'o', 'e', 'i', 'u', 'v', 'er', 
            'ai', 'ei', 'ao', 'ou', 'ia', 'ie', 'ua', 'uo', 've', 
            'iao', 'iou', 'uai', 'uei', 
            'an', 'ian', 'uan', 'van', 
            'en', 'in', 'uen', 'vn', 
            'ang', 'iang', 'uang', 
            'eng', 'ing', 'ueng', 
            'ong', 'iong'
        }
        
        # ä»æ•°æ®ä¸­æ”¶é›†æ‹¼éŸ³å¹¶åˆ†æï¼ˆåªä¿ç•™ç¬¦åˆæ ‡å‡†çš„ï¼‰
        for word_info in self.words_data:
            # ä½¿ç”¨æ–°çš„æ‹¼éŸ³åˆ—è¡¨
            pinyin_list = word_info.get('pinyin_list', [])
            if not pinyin_list:
                continue
                
            for pinyin in pinyin_list:
                if not pinyin:
                    continue
                    
                # å¤„ç†å¤šä¸ªæ‹¼éŸ³ï¼ˆç”¨é€—å·åˆ†éš”ï¼‰
                pinyins = [p.strip() for p in pinyin.split(',')]
                
                for py in pinyins:
                    if not py:
                        continue
                        
                    # éªŒè¯æ‹¼éŸ³æ˜¯å¦ç¬¦åˆæ ‡å‡†å¹¶åˆ†æ
                    if self._is_valid_pinyin(py, standard_initials, standard_finals):
                        self._parse_single_pinyin(py, standard_initials, standard_finals)
        
        # ä½¿ç”¨æ ‡å‡†åˆ—è¡¨ï¼ˆå›ºå®šä¸å˜ï¼‰
        self.initials = [''] + sorted(list(standard_initials))  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤º"ä¸é™åˆ¶"
        self.finals = [''] + sorted(list(standard_finals))
        self.tones = ['', '1', '2', '3', '4', '5']  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤º"ä¸é™åˆ¶"ï¼Œ5è¡¨ç¤ºè½»å£°
    
    def _is_valid_pinyin(self, pinyin: str, standard_initials: set, standard_finals: set) -> bool:
        """éªŒè¯æ‹¼éŸ³æ˜¯å¦ç¬¦åˆæ ‡å‡†å£°æ¯éŸµæ¯ç»„åˆ"""
        if not pinyin:
            return False
        
        # å»é™¤éŸ³è°ƒè·å–åŸºç¡€æ‹¼éŸ³
        base_pinyin = self._remove_tone_marks(pinyin)
        
        # åˆ†ç¦»å£°æ¯å’ŒéŸµæ¯
        initial, final = self._split_initial_final(base_pinyin, standard_initials)
        
        # æ£€æŸ¥éŸµæ¯æ˜¯å¦åœ¨æ ‡å‡†åˆ—è¡¨ä¸­
        if final and final not in standard_finals:
            return False
        
        # æ£€æŸ¥å£°æ¯æ˜¯å¦åœ¨æ ‡å‡†åˆ—è¡¨ä¸­ï¼ˆå¦‚æœæœ‰å£°æ¯çš„è¯ï¼‰
        if initial and initial not in standard_initials:
            return False
        
        return True
    
    def _parse_single_pinyin(self, pinyin: str, standard_initials: Set[str], standard_finals: Set[str]):
        """è§£æå•ä¸ªæ‹¼éŸ³ï¼Œæå–å£°æ¯ã€éŸµæ¯ã€éŸ³è°ƒ"""
        if not pinyin:
            return
            
        # å»é™¤éŸ³è°ƒç¬¦å·ï¼Œæå–éŸ³è°ƒ
        tone = self._extract_tone(pinyin)
        if tone:
            self.tones.add(tone)
        
        # æ³¨æ„ï¼šä¸å†åŠ¨æ€æ·»åŠ å£°æ¯éŸµæ¯ï¼Œå› ä¸ºæˆ‘ä»¬ä½¿ç”¨å›ºå®šçš„æ ‡å‡†åˆ—è¡¨
    
    def _extract_tone(self, pinyin: str) -> str:
        """ä»æ‹¼éŸ³ä¸­æå–éŸ³è°ƒ"""
        # éŸ³è°ƒç¬¦å·æ˜ å°„
        tone_marks = {
            'Ä': '1', 'Ã¡': '2', 'Ç': '3', 'Ã ': '4',
            'Ä“': '1', 'Ã©': '2', 'Ä›': '3', 'Ã¨': '4',
            'Ä«': '1', 'Ã­': '2', 'Ç': '3', 'Ã¬': '4',
            'Å': '1', 'Ã³': '2', 'Ç’': '3', 'Ã²': '4',
            'Å«': '1', 'Ãº': '2', 'Ç”': '3', 'Ã¹': '4',
            'Ç–': '1', 'Ç˜': '2', 'Çš': '3', 'Çœ': '4',
            'Ã¼': '5', 'v': '5'  # è¿™äº›é€šå¸¸è¡¨ç¤ºè½»å£°æˆ–æ— è°ƒ
        }
        
        # æ£€æŸ¥æ•°å­—éŸ³è°ƒ
        if pinyin and pinyin[-1].isdigit():
            return pinyin[-1]
        
        # æ£€æŸ¥éŸ³è°ƒç¬¦å·
        for char in pinyin:
            if char in tone_marks:
                return tone_marks[char]
        
        return '5'  # é»˜è®¤è½»å£°
    
    def _remove_tone_marks(self, pinyin: str) -> str:
        """å»é™¤æ‹¼éŸ³ä¸­çš„éŸ³è°ƒç¬¦å·"""
        # éŸ³è°ƒç¬¦å·åˆ°åŸºæœ¬å­—æ¯çš„æ˜ å°„
        tone_map = {
            'Ä': 'a', 'Ã¡': 'a', 'Ç': 'a', 'Ã ': 'a',
            'Ä“': 'e', 'Ã©': 'e', 'Ä›': 'e', 'Ã¨': 'e',
            'Ä«': 'i', 'Ã­': 'i', 'Ç': 'i', 'Ã¬': 'i',
            'Å': 'o', 'Ã³': 'o', 'Ç’': 'o', 'Ã²': 'o',
            'Å«': 'u', 'Ãº': 'u', 'Ç”': 'u', 'Ã¹': 'u',
            'Ç–': 'v', 'Ç˜': 'v', 'Çš': 'v', 'Çœ': 'v',
            'Ã¼': 'v', 'É¡': 'g'  # ç‰¹æ®Šçš„gå­—ç¬¦
        }
        
        result = ''
        for char in pinyin:
            if char in tone_map:
                result += tone_map[char]
            elif char.isdigit() and char in '12345':
                continue  # è·³è¿‡æ•°å­—éŸ³è°ƒ
            else:
                result += char
                
        return result.lower()
    
    def _split_initial_final(self, pinyin: str, known_initials: Set[str]) -> Tuple[str, str]:
        """åˆ†ç¦»å£°æ¯å’ŒéŸµæ¯"""
        if not pinyin:
            return '', ''
        
        # æŒ‰é•¿åº¦æ’åºï¼Œä¼˜å…ˆåŒ¹é…è¾ƒé•¿çš„å£°æ¯
        sorted_initials = sorted(known_initials, key=len, reverse=True)
        
        for initial in sorted_initials:
            if pinyin.startswith(initial):
                final = pinyin[len(initial):]
                return initial, final
        
        # å¦‚æœæ²¡æœ‰åŒ¹é…çš„å£°æ¯ï¼Œæ•´ä¸ªæ‹¼éŸ³ä½œä¸ºéŸµæ¯
        return '', pinyin
    
    def get_available_options(self) -> Dict[str, List[str]]:
        """è·å–å¯ç”¨çš„æŸ¥è¯¢é€‰é¡¹"""
        return {
            'initials': self.initials,
            'finals': self.finals,
            'tones': self.tones,
            'stroke_names': self.get_available_stroke_names(),
            'radicals': self.get_available_radicals()
        }
    
    def search_characters(self, strokes: Optional[str] = None, initial: Optional[str] = None, 
                         final: Optional[str] = None, tone: Optional[str] = None, 
                         stroke_name: Optional[str] = None, radicals: Optional[List[str]] = None, 
                         max_results: int = 100) -> Tuple[List[Dict], int]:
        """
        æ ¹æ®æ¡ä»¶æœç´¢æ±‰å­—
        
        Args:
            strokes: ç¬”ç”»æ•°
            initial: å£°æ¯
            final: éŸµæ¯
            tone: éŸ³è°ƒ
            stroke_name: ç¬”ç”»åç§°ï¼ˆå¦‚ï¼šæ¨ªã€ç«–ã€æ’‡ã€æºç­‰ï¼‰
            radicals: åæ—éƒ¨é¦–åˆ—è¡¨
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            (åŒ¹é…çš„æ±‰å­—åˆ—è¡¨, æ€»ç»“æœæ•°)
        """
        if not self.words_data:
            return [], 0
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘æä¾›äº†ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not any([strokes, initial, final, tone, stroke_name, radicals]):
            return [], 0
        
        results = []
        stroke_count = None
        
        # å¤„ç†ç¬”ç”»æ•°
        if strokes and strokes.strip():
            try:
                stroke_count = int(strokes.strip())
            except ValueError:
                stroke_count = None
        
        # æ¸…ç†æŸ¥è¯¢æ¡ä»¶
        initial = initial.strip() if initial else ''
        final = final.strip() if final else ''
        tone = tone.strip() if tone else ''
        stroke_name = stroke_name.strip() if stroke_name else ''
        
        # å…ˆæ”¶é›†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ç»“æœ
        for word_info in self.words_data:
            if self._matches_criteria(word_info, stroke_count, initial, final, tone, stroke_name, radicals):
                results.append(word_info)
        
        # è®°å½•æ€»ç»“æœæ•°
        total_count = len(results)
        
        # æŒ‰é‡Šä¹‰é•¿åº¦ä»é•¿åˆ°çŸ­æ’åºï¼ˆé‡Šä¹‰é•¿çš„å­—é€šå¸¸æ›´å¸¸ç”¨ï¼‰
        results.sort(key=lambda x: len(x.get('explanation', '')), reverse=True)
        
        # æœ€åé™åˆ¶ç»“æœæ•°é‡
        limited_results = results[:max_results]
        
        # è¿”å›ç»“æœå’Œæ€»æ•°ä¿¡æ¯
        return limited_results, total_count
    
    def _matches_criteria(self, word_info: Dict, stroke_count: Optional[int], 
                         initial: str, final: str, tone: str, stroke_name: str = '', 
                         radicals: Optional[List[str]] = None) -> bool:
        """æ£€æŸ¥æ±‰å­—æ˜¯å¦åŒ¹é…æŸ¥è¯¢æ¡ä»¶"""
        # æ£€æŸ¥ç¬”ç”»æ•°
        if stroke_count is not None:
            try:
                word_strokes = int(word_info.get('strokes', '0'))
                if word_strokes != stroke_count:
                    return False
            except ValueError:
                if stroke_count > 0:  # å¦‚æœæŒ‡å®šäº†ç¬”ç”»æ•°ä½†æ±‰å­—æ•°æ®æ— æ•ˆï¼Œåˆ™ä¸åŒ¹é…
                    return False
        
        # æ£€æŸ¥ç¬”ç”»åç§°
        if stroke_name:
            if not self._matches_stroke_name(word_info, stroke_name):
                return False
        
        # æ£€æŸ¥åæ—éƒ¨é¦–
        if radicals:
            word_radical = word_info.get('radicals', '').strip()
            if not word_radical or word_radical not in radicals:
                return False
        
        # å¦‚æœæ²¡æœ‰æ‹¼éŸ³æ¡ä»¶ï¼Œåªè¦å…¶ä»–æ¡ä»¶åŒ¹é…å°±è¿”å›True
        if not any([initial, final, tone]):
            return True
        
        # æ£€æŸ¥æ‹¼éŸ³æ¡ä»¶ - å¿…é¡»æœ‰è‡³å°‘ä¸€ä¸ªè¯»éŸ³æ»¡è¶³æ‰€æœ‰æ‹¼éŸ³æ¡ä»¶
        pinyin_list = word_info.get('pinyin_list', [])
        if not pinyin_list:
            return False  # å¦‚æœæœ‰æ‹¼éŸ³æ¡ä»¶ä½†å­—æ²¡æœ‰æ‹¼éŸ³æ•°æ®ï¼Œåˆ™ä¸åŒ¹é…
        
        # å¤„ç†å¤šä¸ªæ‹¼éŸ³è¯»éŸ³
        for pinyin in pinyin_list:
            if not pinyin:
                continue
                
            # å¤„ç†é€—å·åˆ†éš”çš„æ‹¼éŸ³
            pinyins = [p.strip() for p in pinyin.split(',')]
            
            for py in pinyins:
                # åªå¤„ç†ç¬¦åˆæ ‡å‡†çš„æ‹¼éŸ³
                standard_initials = {
                    'b', 'p', 'm', 'f', 'z', 'c', 's', 'd', 't', 'n', 'l', 
                    'zh', 'ch', 'sh', 'r', 'j', 'q', 'x', 'h', 'k', 'g', 'y', 'w'
                }
                standard_finals = {
                    'a', 'o', 'e', 'i', 'u', 'v', 'er', 
                    'ai', 'ei', 'ao', 'ou', 'ia', 'ie', 'ua', 'uo', 've', 
                    'iao', 'iou', 'uai', 'uei', 
                    'an', 'ian', 'uan', 'van', 
                    'en', 'in', 'uen', 'vn', 
                    'ang', 'iang', 'uang', 
                    'eng', 'ing', 'ueng', 
                    'ong', 'iong'
                }
                
                if self._is_valid_pinyin(py, standard_initials, standard_finals) and self._pinyin_matches(py, initial, final, tone):
                    return True
        
        return False
    
    def _pinyin_matches(self, pinyin: str, target_initial: str, 
                       target_final: str, target_tone: str) -> bool:
        """æ£€æŸ¥å•ä¸ªæ‹¼éŸ³æ˜¯å¦åŒ¹é…æ¡ä»¶"""
        if not pinyin:
            return False
        
        # æå–éŸ³è°ƒ
        extracted_tone = self._extract_tone(pinyin)
        
        # æ£€æŸ¥éŸ³è°ƒ
        if target_tone and extracted_tone != target_tone:
            return False
        
        # å»é™¤éŸ³è°ƒè·å–åŸºç¡€æ‹¼éŸ³
        base_pinyin = self._remove_tone_marks(pinyin)
        
        # åˆ†ç¦»å£°æ¯å’ŒéŸµæ¯
        standard_initials = {
            'b', 'p', 'm', 'f', 'z', 'c', 's', 'd', 't', 'n', 'l', 
            'zh', 'ch', 'sh', 'r', 'j', 'q', 'x', 'h', 'k', 'g', 'y', 'w'
        }
        
        extracted_initial, extracted_final = self._split_initial_final(base_pinyin, standard_initials)
        
        # æ£€æŸ¥å£°æ¯
        if target_initial and extracted_initial != target_initial:
            return False
        
        # æ£€æŸ¥éŸµæ¯
        if target_final and extracted_final != target_final:
            return False
        
        return True

    def search_by_stroke_positions(self, stroke_positions: Dict[int, str], max_results: int = 50) -> Tuple[List[Dict], int]:
        """
        æŒ‰æŒ‡å®šä½ç½®çš„ç¬”ç”»æŸ¥æ‰¾æ±‰å­—
        
        Args:
            stroke_positions: ç¬”ç”»ä½ç½®å­—å…¸ï¼Œå¦‚ {1: "æ¨ª", 3: "ç«–", 7: "æ’‡"} è¡¨ç¤ºç¬¬1ç”»æ˜¯æ¨ªï¼Œç¬¬3ç”»æ˜¯ç«–ï¼Œç¬¬7ç”»æ˜¯æ’‡
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            (åŒ¹é…çš„æ±‰å­—åˆ—è¡¨, æ€»ç»“æœæ•°)
        """
        if not self.words_data or not stroke_positions:
            return [], 0
        
        results = []
        
        for word_info in self.words_data:
            if self._matches_stroke_positions(word_info, stroke_positions):
                results.append(word_info)
        
        # è®°å½•æ€»ç»“æœæ•°
        total_count = len(results)
        
        # æŒ‰ç¬”ç”»æ•°ä»å°‘åˆ°å¤šæ’åºï¼Œç¬”ç”»æ•°ç›¸åŒçš„æŒ‰é‡Šä¹‰é•¿åº¦æ’åº
        results.sort(key=lambda x: (
            len(x.get('order_simple', [])), 
            -len(x.get('explanation', ''))
        ))
        
        # é™åˆ¶ç»“æœæ•°é‡
        limited_results = results[:max_results]
        
        return limited_results, total_count
    
    def _matches_stroke_positions(self, word_info: Dict, stroke_positions: Dict[int, str]) -> bool:
        """æ£€æŸ¥æ±‰å­—æ˜¯å¦åŒ¹é…æŒ‡å®šä½ç½®çš„ç¬”ç”»"""
        order_simple = word_info.get('order_simple', [])
        if not order_simple:
            return False
        
        # æ£€æŸ¥æ¯ä¸ªæŒ‡å®šä½ç½®çš„ç¬”ç”»æ˜¯å¦åŒ¹é…
        for position, expected_stroke in stroke_positions.items():
            # ä½ç½®ä»1å¼€å§‹ï¼Œè½¬æ¢ä¸ºæ•°ç»„ç´¢å¼•ï¼ˆä»0å¼€å§‹ï¼‰
            array_index = position - 1
            
            # æ£€æŸ¥ä½ç½®æ˜¯å¦è¶…å‡ºç¬”ç”»æ€»æ•°
            if array_index >= len(order_simple):
                return False
            
            # æ£€æŸ¥è¯¥ä½ç½®çš„ç¬”ç”»æ˜¯å¦åŒ¹é…
            if order_simple[array_index] != expected_stroke:
                return False
        
        return True

    def search_by_stroke_sequence(self, stroke_sequence: List[str], max_results: int = 50) -> Tuple[List[Dict], int]:
        """
        æŒ‰ç¬”ç”»é¡ºåºæŸ¥æ‰¾æ±‰å­—
        
        Args:
            stroke_sequence: ç¬”ç”»åºåˆ—ï¼Œå¦‚ ["æ¨ª", "ç«–", "æ’‡"]
            max_results: æœ€å¤§ç»“æœæ•°
            
        Returns:
            (åŒ¹é…çš„æ±‰å­—åˆ—è¡¨, æ€»ç»“æœæ•°)
        """
        if not self.words_data or not stroke_sequence:
            return [], 0
        
        results = []
        
        # è¿‡æ»¤æ‰ç©ºçš„ç¬”ç”»
        stroke_sequence = [stroke for stroke in stroke_sequence if stroke and stroke.strip()]
        if not stroke_sequence:
            return [], 0
        
        for word_info in self.words_data:
            if self._matches_stroke_sequence(word_info, stroke_sequence):
                results.append(word_info)
        
        # è®°å½•æ€»ç»“æœæ•°
        total_count = len(results)
        
        # æŒ‰ç¬”ç”»æ•°ä»å°‘åˆ°å¤šæ’åºï¼Œç¬”ç”»æ•°ç›¸åŒçš„æŒ‰é‡Šä¹‰é•¿åº¦æ’åº
        results.sort(key=lambda x: (
            len(x.get('order_simple', [])), 
            -len(x.get('explanation', ''))
        ))
        
        # é™åˆ¶ç»“æœæ•°é‡
        limited_results = results[:max_results]
        
        return limited_results, total_count
    
    def _matches_stroke_sequence(self, word_info: Dict, stroke_sequence: List[str]) -> bool:
        """æ£€æŸ¥æ±‰å­—æ˜¯å¦åŒ¹é…æŒ‡å®šçš„ç¬”ç”»åºåˆ—"""
        order_simple = word_info.get('order_simple', [])
        if not order_simple:
            return False
        
        # æ£€æŸ¥ç¬”ç”»åºåˆ—é•¿åº¦
        if len(stroke_sequence) > len(order_simple):
            return False
        
        # æ£€æŸ¥æ¯ä¸ªä½ç½®çš„ç¬”ç”»æ˜¯å¦åŒ¹é…
        for i, expected_stroke in enumerate(stroke_sequence):
            if i >= len(order_simple) or order_simple[i] != expected_stroke:
                return False
        
        return True
    
    def _matches_stroke_name(self, word_info: Dict, stroke_name: str) -> bool:
        """æ£€æŸ¥æ±‰å­—æ˜¯å¦åŒ…å«æŒ‡å®šçš„ç¬”ç”»åç§°"""
        if not stroke_name:
            return True
        
        # è·å–ç®€åŒ–ç¬”ç”»åç§°åˆ—è¡¨
        order_simple = word_info.get('order_simple', [])
        if not order_simple:
            return False
        
        # æ£€æŸ¥æ˜¯å¦åŒ…å«æŒ‡å®šçš„ç¬”ç”»åç§°
        return stroke_name in order_simple
    
    def get_available_stroke_names(self) -> List[str]:
        """è·å–æ•°æ®ä¸­æ‰€æœ‰å¯ç”¨çš„ç¬”ç”»åç§°"""
        stroke_names = set()
        
        for word_info in self.words_data:
            order_simple = word_info.get('order_simple', [])
            if order_simple:
                stroke_names.update(order_simple)
        
        # æŒ‰å¸¸è§ç¬”ç”»é¡ºåºæ’åº
        common_strokes = ['æ¨ª', 'ç«–', 'æ’‡', 'æº', 'ç‚¹', 'æ', 'æ¨ªæŠ˜', 'ç«–é’©', 'æ¨ªé’©', 'æ’‡ç‚¹']
        result = []
        
        # å…ˆæ·»åŠ å¸¸è§ç¬”ç”»
        for stroke in common_strokes:
            if stroke in stroke_names:
                result.append(stroke)
                stroke_names.remove(stroke)
        
        # å†æ·»åŠ å…¶ä»–ç¬”ç”»ï¼ˆæŒ‰å­—æ¯é¡ºåºï¼‰
        result.extend(sorted(stroke_names))
        
        return [''] + result  # ç©ºå­—ç¬¦ä¸²è¡¨ç¤º"ä¸é™åˆ¶"
    
    def get_available_radicals(self) -> List[str]:
        """è·å–æ•°æ®ä¸­æ‰€æœ‰å¯ç”¨çš„åæ—éƒ¨é¦–ï¼ŒæŒ‰å­—æ•°é‡é™åºæ’åˆ—"""
        radical_count = {}
        
        # ç»Ÿè®¡æ¯ä¸ªåæ—å¯¹åº”çš„å­—æ•°é‡
        for word_info in self.words_data:
            radical = word_info.get('radicals', '').strip()
            if radical:
                radical_count[radical] = radical_count.get(radical, 0) + 1
        
        # æŒ‰å­—æ•°é‡é™åºæ’åº
        sorted_radicals = sorted(radical_count.items(), key=lambda x: x[1], reverse=True)
        
        # è¿”å›å¸¦æ•°é‡çš„åæ—åˆ—è¡¨ï¼Œæ–¹ä¾¿ç”¨æˆ·çœ‹åˆ°ä½¿ç”¨é¢‘ç‡
        return [f"{radical} ({count}å­—)" for radical, count in sorted_radicals]
    
    def get_available_radicals_simple(self) -> List[str]:
        """è·å–ç®€å•çš„åæ—åˆ—è¡¨ï¼ˆä¸å¸¦æ•°é‡æ˜¾ç¤ºï¼‰"""
        radical_count = {}
        
        # ç»Ÿè®¡æ¯ä¸ªåæ—å¯¹åº”çš„å­—æ•°é‡
        for word_info in self.words_data:
            radical = word_info.get('radicals', '').strip()
            if radical:
                radical_count[radical] = radical_count.get(radical, 0) + 1
        
        # æŒ‰å­—æ•°é‡é™åºæ’åº
        sorted_radicals = sorted(radical_count.items(), key=lambda x: x[1], reverse=True)
        
        # åªè¿”å›åæ—åˆ—è¡¨ï¼ˆä¸åŒ…å«æ•°é‡ï¼‰
        return [radical for radical, count in sorted_radicals]


def _is_valid_standard_pinyin(pinyin: str, standard_initials: set, standard_finals: set) -> bool:
    """éªŒè¯æ‹¼éŸ³æ˜¯å¦ç¬¦åˆæ ‡å‡†å£°æ¯éŸµæ¯ç»„åˆï¼ˆç‹¬ç«‹å‡½æ•°ç‰ˆæœ¬ï¼‰"""
    if not pinyin:
        return False
    
    # å»é™¤éŸ³è°ƒè·å–åŸºç¡€æ‹¼éŸ³
    tone_map = {
        'Ä': 'a', 'Ã¡': 'a', 'Ç': 'a', 'Ã ': 'a',
        'Ä“': 'e', 'Ã©': 'e', 'Ä›': 'e', 'Ã¨': 'e',
        'Ä«': 'i', 'Ã­': 'i', 'Ç': 'i', 'Ã¬': 'i',
        'Å': 'o', 'Ã³': 'o', 'Ç’': 'o', 'Ã²': 'o',
        'Å«': 'u', 'Ãº': 'u', 'Ç”': 'u', 'Ã¹': 'u',
        'Ç–': 'v', 'Ç˜': 'v', 'Çš': 'v', 'Çœ': 'v',
        'Ã¼': 'v', 'É¡': 'g'
    }
    
    base_pinyin = ''
    for char in pinyin:
        if char in tone_map:
            base_pinyin += tone_map[char]
        elif char.isdigit() and char in '12345':
            continue
        else:
            base_pinyin += char
    base_pinyin = base_pinyin.lower()
    
    # åˆ†ç¦»å£°æ¯å’ŒéŸµæ¯
    sorted_initials = sorted(standard_initials, key=len, reverse=True)
    initial = ''
    final = base_pinyin
    
    for init in sorted_initials:
        if base_pinyin.startswith(init):
            initial = init
            final = base_pinyin[len(init):]
            break
    
    # æ£€æŸ¥éŸµæ¯æ˜¯å¦åœ¨æ ‡å‡†åˆ—è¡¨ä¸­
    if final and final not in standard_finals:
        return False
    
    # æ£€æŸ¥å£°æ¯æ˜¯å¦åœ¨æ ‡å‡†åˆ—è¡¨ä¸­ï¼ˆå¦‚æœæœ‰å£°æ¯çš„è¯ï¼‰
    if initial and initial not in standard_initials:
        return False
    
    return True


def process_stroke_positions_search(stroke_positions: Dict[int, str], max_results: int = 50) -> str:
    """
    å¤„ç†æŒ‡å®šä½ç½®ç¬”ç”»æŸ¥æ±‰å­—è¯·æ±‚
    
    Args:
        stroke_positions: ç¬”ç”»ä½ç½®å­—å…¸ï¼Œå¦‚ {1: "æ¨ª", 3: "ç«–", 7: "æ’‡"}
        max_results: æœ€å¤§ç»“æœæ•°
        
    Returns:
        æŸ¥è¯¢ç»“æœå­—ç¬¦ä¸²
    """
    try:
        searcher = PinyinSearcher()
        
        if not stroke_positions:
            return "âŒ è¯·è‡³å°‘æŒ‡å®šä¸€ä¸ªç¬”ç”»ä½ç½®"
        
        results, total_count = searcher.search_by_stroke_positions(stroke_positions, max_results)
        
        if not results:
            # ç”Ÿæˆæ¡ä»¶æè¿°
            conditions = []
            for pos in sorted(stroke_positions.keys()):
                conditions.append(f"ç¬¬{pos}ç”»={stroke_positions[pos]}")
            condition_str = ", ".join(conditions)
            return f"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶ [{condition_str}] çš„æ±‰å­—"
        
        # æ ¼å¼åŒ–è¾“å‡ºç»“æœ
        conditions = []
        for pos in sorted(stroke_positions.keys()):
            conditions.append(f"ç¬¬{pos}ç”»={stroke_positions[pos]}")
        condition_str = ", ".join(conditions)
        
        if total_count > len(results):
            output_lines = [f"ğŸ” æ‰¾åˆ° {total_count} ä¸ªç¬¦åˆæ¡ä»¶ [{condition_str}] çš„æ±‰å­—ï¼Œæ˜¾ç¤ºå‰ {len(results)} ä¸ª:\n"]
        else:
            output_lines = [f"ğŸ” æ‰¾åˆ° {len(results)} ä¸ªç¬¦åˆæ¡ä»¶ [{condition_str}] çš„æ±‰å­—:\n"]
        
        # æ·»åŠ æŸ¥è¯¢æ¡ä»¶è¯´æ˜
        output_lines.append(f"ğŸ“‹ æŸ¥è¯¢æ¡ä»¶: {condition_str}\n")
        
        # æ ¼å¼åŒ–æ±‰å­—ç»“æœ
        output_lines.append("ğŸ“ æŸ¥è¯¢ç»“æœ:")
        for i, word_info in enumerate(results, 1):
            word = word_info.get('word', '?')
            
            # è·å–æ‹¼éŸ³ä¿¡æ¯
            pinyin_list = word_info.get('pinyin_list', [])
            if not pinyin_list:
                pinyin_list = [word_info.get('pinyin', 'æ— ')]
            
            # è¿‡æ»¤å¹¶åˆå¹¶æ‰€æœ‰ç¬¦åˆæ ‡å‡†çš„è¯»éŸ³æ˜¾ç¤º
            standard_initials = {
                'b', 'p', 'm', 'f', 'z', 'c', 's', 'd', 't', 'n', 'l', 
                'zh', 'ch', 'sh', 'r', 'j', 'q', 'x', 'h', 'k', 'g', 'y', 'w'
            }
            standard_finals = {
                'a', 'o', 'e', 'i', 'u', 'v', 'er', 
                'ai', 'ei', 'ao', 'ou', 'ia', 'ie', 'ua', 'uo', 've', 
                'iao', 'iou', 'uai', 'uei', 
                'an', 'ian', 'uan', 'van', 
                'en', 'in', 'vn', 
                'ang', 'iang', 'uang', 
                'eng', 'ing', 
                'ong', 'iong'
            }
            
            all_pinyins = []
            for p in pinyin_list:
                if p:
                    for py in [py.strip() for py in p.split(',')]:
                        if _is_valid_standard_pinyin(py, standard_initials, standard_finals):
                            all_pinyins.append(py)
            
            # å»é‡ä½†ä¿æŒé¡ºåºï¼Œæ˜¾ç¤ºå¤šéŸ³å­—çš„æ‰€æœ‰è¯»éŸ³
            seen = set()
            unique_pinyins = []
            for py in all_pinyins:
                if py not in seen:
                    seen.add(py)
                    unique_pinyins.append(py)
            
            # å¦‚æœæœ‰å¤šä¸ªè¯»éŸ³ï¼Œç”¨ç‰¹æ®Šæ ¼å¼æ ‡è®°å¤šéŸ³å­—
            if len(unique_pinyins) > 1:
                pinyin_display = f"[å¤šéŸ³å­—] {' / '.join(unique_pinyins)}"
            elif unique_pinyins:
                pinyin_display = unique_pinyins[0]
            else:
                pinyin_display = 'æ— '
            
            strokes_info = word_info.get('strokes', '?')
            radical = word_info.get('radicals', '?')
            
            # è·å–ç¬”é¡ºä¿¡æ¯å¹¶é«˜äº®åŒ¹é…çš„ä½ç½®
            order_simple = word_info.get('order_simple', [])
            stroke_order_display = ''
            if order_simple:
                # åˆ›å»ºé«˜äº®æ˜¾ç¤ºçš„ç¬”é¡º
                highlighted_strokes = []
                for idx, stroke in enumerate(order_simple):
                    position = idx + 1  # è½¬æ¢ä¸º1å¼€å§‹çš„ä½ç½®
                    if position in stroke_positions:
                        highlighted_strokes.append(f"[{stroke}]")  # é«˜äº®åŒ¹é…çš„ç¬”ç”»
                    else:
                        highlighted_strokes.append(stroke)
                
                if len(order_simple) <= 10:
                    stroke_order_display = f", ç¬”é¡º: {'â†’'.join(highlighted_strokes)}"
                else:
                    # å¯¹äºé•¿ç¬”é¡ºï¼Œæ˜¾ç¤ºå‰å‡ ç”»å’ŒåŒ¹é…çš„ä½ç½®
                    display_strokes = highlighted_strokes[:8]
                    stroke_order_display = f", ç¬”é¡º: {'â†’'.join(display_strokes)}â†’...å…±{len(order_simple)}ç¬”"
            
            explanation = word_info.get('explanation', '')
            if explanation:
                explanation = ' '.join(line.strip() for line in explanation.split('\n') if line.strip())
                if len(explanation) > 200:
                    explanation = explanation[:200] + '...'
            else:
                explanation = 'æ— é‡Šä¹‰'
            
            output_lines.append(f"  {i:2d}. {word} ({pinyin_display}, {strokes_info}ç¬”, éƒ¨é¦–:{radical}{stroke_order_display})")
            output_lines.append(f"     {explanation}")
        
        return '\n'.join(output_lines)
    
    except Exception as e:
        return f"âŒ æŸ¥è¯¢å‡ºé”™: {str(e)}"


def process_stroke_sequence_search(stroke_sequence: List[str], max_results: int = 50) -> str:
    """
    å¤„ç†ç¬”ç”»åºåˆ—æŸ¥æ±‰å­—è¯·æ±‚
    
    Args:
        stroke_sequence: ç¬”ç”»åºåˆ—ï¼Œå¦‚ ["æ¨ª", "ç«–", "æ’‡"]
        max_results: æœ€å¤§ç»“æœæ•°
        
    Returns:
        æŸ¥è¯¢ç»“æœå­—ç¬¦ä¸²
    """
    try:
        searcher = PinyinSearcher()
        
        # è¿‡æ»¤ç©ºå€¼
        filtered_sequence = [stroke for stroke in stroke_sequence if stroke and stroke.strip()]
        
        if not filtered_sequence:
            return "âŒ è¯·è‡³å°‘æŒ‡å®šä¸€ä¸ªç¬”ç”»"
        
        results, total_count = searcher.search_by_stroke_sequence(filtered_sequence, max_results)
        
        if not results:
            sequence_str = "â†’".join(filtered_sequence)
            return f"âŒ æœªæ‰¾åˆ°ä»¥ [{sequence_str}] å¼€å¤´çš„æ±‰å­—"
        
        # æ ¼å¼åŒ–è¾“å‡ºç»“æœ
        sequence_str = "â†’".join(filtered_sequence)
        if total_count > len(results):
            output_lines = [f"ğŸ” æ‰¾åˆ° {total_count} ä¸ªä»¥ [{sequence_str}] å¼€å¤´çš„æ±‰å­—ï¼Œæ˜¾ç¤ºå‰ {len(results)} ä¸ª:\n"]
        else:
            output_lines = [f"ğŸ” æ‰¾åˆ° {len(results)} ä¸ªä»¥ [{sequence_str}] å¼€å¤´çš„æ±‰å­—:\n"]
        
        # æ·»åŠ æŸ¥è¯¢æ¡ä»¶è¯´æ˜
        output_lines.append(f"ğŸ“‹ æŸ¥è¯¢æ¡ä»¶: å‰{len(filtered_sequence)}ç”»ä¸º {sequence_str}\n")
        
        # æ ¼å¼åŒ–æ±‰å­—ç»“æœ
        output_lines.append("ğŸ“ æŸ¥è¯¢ç»“æœ:")
        for i, word_info in enumerate(results, 1):
            word = word_info.get('word', '?')
            
            # è·å–æ‹¼éŸ³ä¿¡æ¯
            pinyin_list = word_info.get('pinyin_list', [])
            if not pinyin_list:
                pinyin_list = [word_info.get('pinyin', 'æ— ')]
            
            # è¿‡æ»¤å¹¶åˆå¹¶æ‰€æœ‰ç¬¦åˆæ ‡å‡†çš„è¯»éŸ³æ˜¾ç¤º
            standard_initials = {
                'b', 'p', 'm', 'f', 'z', 'c', 's', 'd', 't', 'n', 'l', 
                'zh', 'ch', 'sh', 'r', 'j', 'q', 'x', 'h', 'k', 'g', 'y', 'w'
            }
            standard_finals = {
                'a', 'o', 'e', 'i', 'u', 'v', 'er', 
                'ai', 'ei', 'ao', 'ou', 'ia', 'ie', 'ua', 'uo', 've', 
                'iao', 'iou', 'uai', 'uei', 
                'an', 'ian', 'uan', 'van', 
                'en', 'in', 'vn', 
                'ang', 'iang', 'uang', 
                'eng', 'ing', 
                'ong', 'iong'
            }
            
            all_pinyins = []
            for p in pinyin_list:
                if p:
                    for py in [py.strip() for py in p.split(',')]:
                        if _is_valid_standard_pinyin(py, standard_initials, standard_finals):
                            all_pinyins.append(py)
            
            # å»é‡ä½†ä¿æŒé¡ºåºï¼Œæ˜¾ç¤ºå¤šéŸ³å­—çš„æ‰€æœ‰è¯»éŸ³
            seen = set()
            unique_pinyins = []
            for py in all_pinyins:
                if py not in seen:
                    seen.add(py)
                    unique_pinyins.append(py)
            
            # å¦‚æœæœ‰å¤šä¸ªè¯»éŸ³ï¼Œç”¨ç‰¹æ®Šæ ¼å¼æ ‡è®°å¤šéŸ³å­—
            if len(unique_pinyins) > 1:
                pinyin_display = f"[å¤šéŸ³å­—] {' / '.join(unique_pinyins)}"
            elif unique_pinyins:
                pinyin_display = unique_pinyins[0]
            else:
                pinyin_display = 'æ— '
            
            strokes_info = word_info.get('strokes', '?')
            radical = word_info.get('radicals', '?')
            
            # è·å–å®Œæ•´ç¬”é¡ºä¿¡æ¯
            order_simple = word_info.get('order_simple', [])
            stroke_order_display = ''
            if order_simple:
                # é«˜äº®åŒ¹é…çš„éƒ¨åˆ†
                matched_part = "â†’".join(order_simple[:len(filtered_sequence)])
                remaining_part = "â†’".join(order_simple[len(filtered_sequence):]) if len(order_simple) > len(filtered_sequence) else ""
                
                if remaining_part:
                    stroke_order_display = f", ç¬”é¡º: [{matched_part}]â†’{remaining_part}"
                else:
                    stroke_order_display = f", ç¬”é¡º: [{matched_part}]"
            
            explanation = word_info.get('explanation', '')
            if explanation:
                # åˆ é™¤ç©ºè¡Œï¼Œåˆå¹¶å¤šè¡Œä¸ºä¸€è¡Œï¼Œç”¨ç©ºæ ¼åˆ†éš”
                explanation = ' '.join(line.strip() for line in explanation.split('\n') if line.strip())
                # å¦‚æœé‡Šä¹‰å¤ªé•¿åˆ™æˆªæ–­
                if len(explanation) > 200:
                    explanation = explanation[:200] + "..."
            else:
                explanation = "æ— é‡Šä¹‰"
            
            # æ·»åŠ å­—ä¸å­—ä¹‹é—´çš„åˆ†å‰²çº¿ï¼ˆé™¤äº†ç¬¬ä¸€ä¸ªå­—ï¼‰
            if i > 1:
                output_lines.append("     " + "â”€" * 60)
            
            output_lines.append(
                f"{i:3d}. {word} ({pinyin_display}, {strokes_info}ç¬”, éƒ¨é¦–:{radical}{stroke_order_display})"
            )
            output_lines.append(f"     é‡Šä¹‰: {explanation}")
        
        if total_count > len(results):
            output_lines.append(f"\nğŸ’¡ å…±æ‰¾åˆ° {total_count} ä¸ªç»“æœï¼Œå·²æ˜¾ç¤ºå‰ {len(results)} ä¸ªæœ€åŒ¹é…çš„æ±‰å­—")
            output_lines.append(f"   å¦‚éœ€æŸ¥çœ‹æ›´å¤šç»“æœï¼Œè¯·è°ƒæ•´æœ€å¤§ç»“æœæ•°")
        
        return "\n".join(output_lines)
        
    except Exception as e:
        return f"âŒ æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


def process_combined_search(strokes: str = "", initial: str = "", final: str = "", tone: str = "", 
                          stroke_positions: Dict[int, str] = None, radicals: List[str] = None, 
                          max_results: int = 50) -> str:
    """
    å¤„ç†ç»„åˆæŸ¥è¯¢ï¼šåŒæ—¶æ”¯æŒæ‹¼éŸ³æ¡ä»¶ã€ç¬”ç”»ä½ç½®æ¡ä»¶å’Œåæ—æ¡ä»¶
    
    Args:
        strokes: ç¬”ç”»æ•°
        initial: å£°æ¯
        final: éŸµæ¯
        tone: éŸ³è°ƒ
        stroke_positions: ç¬”ç”»ä½ç½®å­—å…¸ï¼Œå¦‚ {1: "æ¨ª", 3: "ç«–", 7: "æ’‡"}
        radicals: åæ—éƒ¨é¦–åˆ—è¡¨
        max_results: æœ€å¤§ç»“æœæ•°
        
    Returns:
        æŸ¥è¯¢ç»“æœå­—ç¬¦ä¸²
    """
    try:
        searcher = PinyinSearcher()
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘æä¾›äº†ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        has_pinyin_conditions = any([
            strokes and strokes.strip(), 
            initial and initial.strip(), 
            final and final.strip(), 
            tone and tone.strip()
        ])
        
        has_stroke_positions = stroke_positions and len(stroke_positions) > 0
        has_radicals = radicals and len(radicals) > 0
        
        if not has_pinyin_conditions and not has_stroke_positions and not has_radicals:
            return "âŒ è¯·è‡³å°‘æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶ï¼ˆæ‹¼éŸ³ä¿¡æ¯ã€ç¬”ç”»ä½ç½®æˆ–åæ—éƒ¨é¦–ï¼‰"
        
        # æ”¶é›†æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„ç»“æœ
        all_results = []
        
        # å¤„ç†åæ—åˆ—è¡¨ï¼Œå»é™¤æ•°é‡ä¿¡æ¯
        clean_radicals = None
        if radicals:
            clean_radicals = []
            for radical in radicals:
                # å¦‚æœåæ—åŒ…å«æ•°é‡ä¿¡æ¯ï¼ˆæ ¼å¼å¦‚"å£ (542å­—)"ï¼‰ï¼Œæå–çº¯åæ—åç§°
                if ' (' in radical and radical.endswith('å­—)'):
                    clean_radical = radical.split(' (')[0]
                    clean_radicals.append(clean_radical)
                else:
                    # å¦åˆ™ç›´æ¥ä½¿ç”¨åŸåæ—åç§°
                    clean_radicals.append(radical)
        
        # å…ˆé€šè¿‡æ‹¼éŸ³æ¡ä»¶æˆ–åæ—æ¡ä»¶ç­›é€‰
        if has_pinyin_conditions or has_radicals:
            pinyin_results, _ = searcher.search_characters(strokes, initial, final, tone, "", clean_radicals, max_results * 2)
            all_results = pinyin_results
        else:
            # å¦‚æœæ²¡æœ‰æ‹¼éŸ³æ¡ä»¶å’Œåæ—æ¡ä»¶ï¼Œè·å–æ‰€æœ‰æ±‰å­—
            all_results = searcher.words_data
        
        # å†é€šè¿‡ç¬”ç”»ä½ç½®æ¡ä»¶ç­›é€‰
        if has_stroke_positions:
            filtered_results = []
            for word_info in all_results:
                if searcher._matches_stroke_positions(word_info, stroke_positions):
                    filtered_results.append(word_info)
            all_results = filtered_results
        
        if not all_results:
            # ç”Ÿæˆæ¡ä»¶æè¿°
            conditions = []
            if strokes and strokes.strip():
                conditions.append(f"ç¬”ç”»æ•°: {strokes}")
            if initial and initial.strip():
                conditions.append(f"å£°æ¯: {initial}")
            if final and final.strip():
                conditions.append(f"éŸµæ¯: {final}")
            if tone and tone.strip():
                tone_names = {'1': 'ä¸€å£°', '2': 'äºŒå£°', '3': 'ä¸‰å£°', '4': 'å››å£°', '5': 'è½»å£°'}
                tone_name = tone_names.get(tone, f"{tone}å£°")
                conditions.append(f"éŸ³è°ƒ: {tone_name}")
            if has_radicals:
                # æ˜¾ç¤ºæ—¶ä¹Ÿä½¿ç”¨æ¸…ç†åçš„åæ—åç§°
                display_radicals = [r.split(' (')[0] if ' (' in r and r.endswith('å­—)') else r for r in radicals]
                conditions.append(f"åæ—: {', '.join(display_radicals)}")
            if has_stroke_positions:
                stroke_conds = []
                for pos in sorted(stroke_positions.keys()):
                    stroke_conds.append(f"ç¬¬{pos}ç”»={stroke_positions[pos]}")
                conditions.append(", ".join(stroke_conds))
            
            condition_str = " | ".join(conditions)
            return f"âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶ [{condition_str}] çš„æ±‰å­—"
        
        # è®°å½•æ€»ç»“æœæ•°
        total_count = len(all_results)
        
        # æŒ‰ç¬”ç”»æ•°ä»å°‘åˆ°å¤šæ’åºï¼Œç¬”ç”»æ•°ç›¸åŒçš„æŒ‰é‡Šä¹‰é•¿åº¦æ’åº
        all_results.sort(key=lambda x: (
            int(x.get('strokes', '0')) if x.get('strokes', '0').isdigit() else 999,
            -len(x.get('explanation', ''))
        ))
        
        # é™åˆ¶ç»“æœæ•°é‡
        limited_results = all_results[:max_results]
        
        # æ ¼å¼åŒ–è¾“å‡ºç»“æœ
        conditions = []
        if strokes and strokes.strip():
            conditions.append(f"ç¬”ç”»æ•°: {strokes}")
        if initial and initial.strip():
            conditions.append(f"å£°æ¯: {initial}")
        if final and final.strip():
            conditions.append(f"éŸµæ¯: {final}")
        if tone and tone.strip():
            tone_names = {'1': 'ä¸€å£°', '2': 'äºŒå£°', '3': 'ä¸‰å£°', '4': 'å››å£°', '5': 'è½»å£°'}
            tone_name = tone_names.get(tone, f"{tone}å£°")
            conditions.append(f"éŸ³è°ƒ: {tone_name}")
        if has_radicals:
            conditions.append(f"åæ—: {', '.join(radicals)}")
        if has_stroke_positions:
            stroke_conds = []
            for pos in sorted(stroke_positions.keys()):
                stroke_conds.append(f"ç¬¬{pos}ç”»={stroke_positions[pos]}")
            conditions.append(", ".join(stroke_conds))
        
        condition_str = " | ".join(conditions)
        
        if total_count > len(limited_results):
            output_lines = [f"ğŸ” æ‰¾åˆ° {total_count} ä¸ªç¬¦åˆæ¡ä»¶ [{condition_str}] çš„æ±‰å­—ï¼Œæ˜¾ç¤ºå‰ {len(limited_results)} ä¸ª:\n"]
        else:
            output_lines = [f"ğŸ” æ‰¾åˆ° {len(limited_results)} ä¸ªç¬¦åˆæ¡ä»¶ [{condition_str}] çš„æ±‰å­—:\n"]
        
        # æ·»åŠ æŸ¥è¯¢æ¡ä»¶è¯´æ˜
        output_lines.append(f"ğŸ“‹ æŸ¥è¯¢æ¡ä»¶: {condition_str}\n")
        
        # æ ¼å¼åŒ–æ±‰å­—ç»“æœ
        output_lines.append("ğŸ“ æŸ¥è¯¢ç»“æœ:")
        for i, word_info in enumerate(limited_results, 1):
            word = word_info.get('word', '?')
            
            # è·å–æ‹¼éŸ³ä¿¡æ¯
            pinyin_list = word_info.get('pinyin_list', [])
            if not pinyin_list:
                pinyin_list = [word_info.get('pinyin', 'æ— ')]
            
            # è¿‡æ»¤å¹¶åˆå¹¶æ‰€æœ‰ç¬¦åˆæ ‡å‡†çš„è¯»éŸ³æ˜¾ç¤º
            standard_initials = {
                'b', 'p', 'm', 'f', 'z', 'c', 's', 'd', 't', 'n', 'l', 
                'zh', 'ch', 'sh', 'r', 'j', 'q', 'x', 'h', 'k', 'g', 'y', 'w'
            }
            standard_finals = {
                'a', 'o', 'e', 'i', 'u', 'v', 'er', 
                'ai', 'ei', 'ao', 'ou', 'ia', 'ie', 'ua', 'uo', 've', 
                'iao', 'iou', 'uai', 'uei', 
                'an', 'ian', 'uan', 'van', 
                'en', 'in', 'vn', 
                'ang', 'iang', 'uang', 
                'eng', 'ing', 
                'ong', 'iong'
            }
            
            all_pinyins = []
            for p in pinyin_list:
                if p:
                    for py in [py.strip() for py in p.split(',')]:
                        if _is_valid_standard_pinyin(py, standard_initials, standard_finals):
                            all_pinyins.append(py)
            
            # å»é‡ä½†ä¿æŒé¡ºåºï¼Œæ˜¾ç¤ºå¤šéŸ³å­—çš„æ‰€æœ‰è¯»éŸ³
            seen = set()
            unique_pinyins = []
            for py in all_pinyins:
                if py not in seen:
                    seen.add(py)
                    unique_pinyins.append(py)
            
            # å¦‚æœæœ‰å¤šä¸ªè¯»éŸ³ï¼Œç”¨ç‰¹æ®Šæ ¼å¼æ ‡è®°å¤šéŸ³å­—
            if len(unique_pinyins) > 1:
                pinyin_display = f"[å¤šéŸ³å­—] {' / '.join(unique_pinyins)}"
            elif unique_pinyins:
                pinyin_display = unique_pinyins[0]
            else:
                pinyin_display = 'æ— '
            
            strokes_info = word_info.get('strokes', '?')
            radical = word_info.get('radicals', '?')
            
            # è·å–ç¬”é¡ºä¿¡æ¯å¹¶é«˜äº®åŒ¹é…çš„ä½ç½®
            order_simple = word_info.get('order_simple', [])
            stroke_order_display = ''
            if order_simple:
                # åˆ›å»ºé«˜äº®æ˜¾ç¤ºçš„ç¬”é¡º
                highlighted_strokes = []
                for idx, stroke in enumerate(order_simple):
                    position = idx + 1  # è½¬æ¢ä¸º1å¼€å§‹çš„ä½ç½®
                    if has_stroke_positions and position in stroke_positions:
                        highlighted_strokes.append(f"[{stroke}]")  # é«˜äº®åŒ¹é…çš„ç¬”ç”»
                    else:
                        highlighted_strokes.append(stroke)
                
                if len(order_simple) <= 10:
                    stroke_order_display = f", ç¬”é¡º: {'â†’'.join(highlighted_strokes)}"
                else:
                    # å¯¹äºé•¿ç¬”é¡ºï¼Œæ˜¾ç¤ºå‰å‡ ç”»å’ŒåŒ¹é…çš„ä½ç½®
                    display_strokes = highlighted_strokes[:8]
                    stroke_order_display = f", ç¬”é¡º: {'â†’'.join(display_strokes)}â†’...å…±{len(order_simple)}ç¬”"
            
            explanation = word_info.get('explanation', '')
            if explanation:
                explanation = ' '.join(line.strip() for line in explanation.split('\n') if line.strip())
                if len(explanation) > 200:
                    explanation = explanation[:200] + '...'
            else:
                explanation = 'æ— é‡Šä¹‰'
            
            output_lines.append(f"  {i:2d}. {word} ({pinyin_display}, {strokes_info}ç¬”, éƒ¨é¦–:{radical}{stroke_order_display})")
            output_lines.append(f"     {explanation}")
        
        return '\n'.join(output_lines)
    
    except Exception as e:
        return f"âŒ æŸ¥è¯¢å‡ºé”™: {str(e)}"


def process_pinyin_search(strokes: str, initial: str, final: str, tone: str, 
                         stroke_name: str = '', max_results: int = 100) -> str:
    """
    å¤„ç†æ‹¼éŸ³æŸ¥æ±‰å­—è¯·æ±‚
    
    Args:
        strokes: ç¬”ç”»æ•°
        initial: å£°æ¯
        final: éŸµæ¯
        tone: éŸ³è°ƒ
        stroke_name: ç¬”ç”»åç§°
        max_results: æœ€å¤§ç»“æœæ•°
        
    Returns:
        æŸ¥è¯¢ç»“æœå­—ç¬¦ä¸²
    """
    try:
        searcher = PinyinSearcher()
        
        # æ£€æŸ¥æ˜¯å¦è‡³å°‘æä¾›äº†ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶
        if not any([strokes and strokes.strip(), 
                   initial and initial.strip(), 
                   final and final.strip(), 
                   tone and tone.strip(),
                   stroke_name and stroke_name.strip()]):
            return "âŒ è¯·è‡³å°‘æä¾›ä¸€ä¸ªæŸ¥è¯¢æ¡ä»¶ï¼ˆç¬”ç”»æ•°ã€å£°æ¯ã€éŸµæ¯ã€éŸ³è°ƒæˆ–ç¬”ç”»åç§°ï¼‰"
        
        results, total_count = searcher.search_characters(strokes, initial, final, tone, stroke_name, max_results)
        
        if not results:
            return "âŒ æœªæ‰¾åˆ°ç¬¦åˆæ¡ä»¶çš„æ±‰å­—"
        
        # æ ¼å¼åŒ–è¾“å‡ºç»“æœ
        if total_count > len(results):
            output_lines = [f"ğŸ” æ‰¾åˆ° {total_count} ä¸ªç¬¦åˆæ¡ä»¶çš„æ±‰å­—ï¼Œæ˜¾ç¤ºå‰ {len(results)} ä¸ª:\n"]
        else:
            output_lines = [f"ğŸ” æ‰¾åˆ° {len(results)} ä¸ªç¬¦åˆæ¡ä»¶çš„æ±‰å­—:\n"]
        
        # æ·»åŠ æŸ¥è¯¢æ¡ä»¶è¯´æ˜
        conditions = []
        if strokes and strokes.strip():
            conditions.append(f"ç¬”ç”»æ•°: {strokes}")
        if initial and initial.strip():
            conditions.append(f"å£°æ¯: {initial}")
        if final and final.strip():
            conditions.append(f"éŸµæ¯: {final}")
        if tone and tone.strip():
            tone_names = {'1': 'ä¸€å£°', '2': 'äºŒå£°', '3': 'ä¸‰å£°', '4': 'å››å£°', '5': 'è½»å£°'}
            tone_name = tone_names.get(tone, f"{tone}å£°")
            conditions.append(f"éŸ³è°ƒ: {tone_name}")
        if stroke_name and stroke_name.strip():
            conditions.append(f"åŒ…å«ç¬”ç”»: {stroke_name}")
        
        if conditions:
            output_lines.append(f"ğŸ“‹ æŸ¥è¯¢æ¡ä»¶: {' | '.join(conditions)}\n")
        
        # æ ¼å¼åŒ–æ±‰å­—ç»“æœ
        output_lines.append("ğŸ“ æŸ¥è¯¢ç»“æœ:")
        for i, word_info in enumerate(results, 1):
            word = word_info.get('word', '?')
            # ä½¿ç”¨æ‹¼éŸ³åˆ—è¡¨ï¼Œå¦‚æœæ²¡æœ‰åˆ™å›é€€åˆ°åŸå§‹pinyinå­—æ®µ
            pinyin_list = word_info.get('pinyin_list', [])
            if not pinyin_list:
                pinyin_list = [word_info.get('pinyin', 'æ— ')]
            
            # è¿‡æ»¤å¹¶åˆå¹¶æ‰€æœ‰ç¬¦åˆæ ‡å‡†çš„è¯»éŸ³æ˜¾ç¤º
            standard_initials = {
                'b', 'p', 'm', 'f', 'z', 'c', 's', 'd', 't', 'n', 'l', 
                'zh', 'ch', 'sh', 'r', 'j', 'q', 'x', 'h', 'k', 'g', 'y', 'w'
            }
            standard_finals = {
                'a', 'o', 'e', 'i', 'u', 'v', 'er', 
                'ai', 'ei', 'ao', 'ou', 'ia', 'ie', 'ua', 'uo', 've', 
                'iao', 'iou', 'uai', 'uei', 
                'an', 'ian', 'uan', 'van', 
                'en', 'in', 'vn', 
                'ang', 'iang', 'uang', 
                'eng', 'ing', 
                'ong', 'iong'
            }
            
            all_pinyins = []
            for p in pinyin_list:
                if p:
                    for py in [py.strip() for py in p.split(',')]:
                        # ç®€å•éªŒè¯ï¼šå»é™¤éŸ³è°ƒåæ£€æŸ¥æ˜¯å¦ç¬¦åˆæ ‡å‡†
                        if _is_valid_standard_pinyin(py, standard_initials, standard_finals):
                            all_pinyins.append(py)
            
            # å»é‡ä½†ä¿æŒé¡ºåºï¼Œæ˜¾ç¤ºå¤šéŸ³å­—çš„æ‰€æœ‰è¯»éŸ³
            seen = set()
            unique_pinyins = []
            for py in all_pinyins:
                if py not in seen:
                    seen.add(py)
                    unique_pinyins.append(py)
            
            # å¦‚æœæœ‰å¤šä¸ªè¯»éŸ³ï¼Œç”¨ç‰¹æ®Šæ ¼å¼æ ‡è®°å¤šéŸ³å­—
            if len(unique_pinyins) > 1:
                pinyin_display = f"[å¤šéŸ³å­—] {' / '.join(unique_pinyins)}"
            elif unique_pinyins:
                pinyin_display = unique_pinyins[0]
            else:
                pinyin_display = 'æ— '
            
            strokes_info = word_info.get('strokes', '?')
            radical = word_info.get('radicals', '?')
            
            # è·å–ç¬”é¡ºä¿¡æ¯
            order_simple = word_info.get('order_simple', [])
            stroke_order_display = ''
            if order_simple:
                if len(order_simple) <= 10:
                    stroke_order_display = f", ç¬”é¡º: {'â†’'.join(order_simple)}"
                else:
                    stroke_order_display = f", ç¬”é¡º: {'â†’'.join(order_simple[:8])}â†’...å…±{len(order_simple)}ç¬”"
            
            explanation = word_info.get('explanation', '')
            if explanation:
                # åˆ é™¤ç©ºè¡Œï¼Œåˆå¹¶å¤šè¡Œä¸ºä¸€è¡Œï¼Œç”¨ç©ºæ ¼åˆ†éš”
                explanation = ' '.join(line.strip() for line in explanation.split('\n') if line.strip())
                # å¦‚æœé‡Šä¹‰å¤ªé•¿åˆ™æˆªæ–­
                if len(explanation) > 200:
                    explanation = explanation[:200] + "..."
            else:
                explanation = "æ— é‡Šä¹‰"
            
            # æ·»åŠ å­—ä¸å­—ä¹‹é—´çš„åˆ†å‰²çº¿ï¼ˆé™¤äº†ç¬¬ä¸€ä¸ªå­—ï¼‰
            if i > 1:
                output_lines.append("     " + "â”€" * 60)
            
            output_lines.append(
                f"{i:3d}. {word} ({pinyin_display}, {strokes_info}ç¬”, éƒ¨é¦–:{radical}{stroke_order_display})"
            )
            output_lines.append(f"     é‡Šä¹‰: {explanation}")
        
        if total_count > len(results):
            output_lines.append(f"\nğŸ’¡ å…±æ‰¾åˆ° {total_count} ä¸ªç»“æœï¼Œå·²æ˜¾ç¤ºå‰ {len(results)} ä¸ªæœ€ç›¸å…³çš„æ±‰å­—")
            output_lines.append(f"   å¦‚éœ€æŸ¥çœ‹æ›´å¤šç»“æœï¼Œè¯·è°ƒæ•´æœ€å¤§ç»“æœæ•°æˆ–ç»†åŒ–æŸ¥è¯¢æ¡ä»¶")
        
        return "\n".join(output_lines)
        
    except Exception as e:
        return f"âŒ æŸ¥è¯¢æ—¶å‘ç”Ÿé”™è¯¯: {str(e)}"


# æµ‹è¯•ä»£ç 
if __name__ == "__main__":
    # æµ‹è¯•åŠŸèƒ½
    searcher = PinyinSearcher()
    
    # æµ‹è¯•1: æŸ¥è¯¢3ç¬”ç”»çš„å­—
    print("=== æµ‹è¯•1: æŸ¥è¯¢3ç¬”ç”»çš„å­— ===")
    result = process_pinyin_search("3", "", "", "", "", 10)
    print(result)
    
    print("\n=== æµ‹è¯•2: æŸ¥è¯¢å£°æ¯ä¸º'zh'çš„å­— ===")
    result = process_pinyin_search("", "zh", "", "", "", 10)
    print(result)
    
    print("\n=== æµ‹è¯•3: æŸ¥è¯¢éŸµæ¯ä¸º'ang'å››å£°çš„å­— ===")
    result = process_pinyin_search("", "", "ang", "4", "", 10)
    print(result)
    
    print("\n=== æµ‹è¯•4: æŸ¥è¯¢åŒ…å«'æ¨ª'ç¬”ç”»çš„å­— ===")
    result = process_pinyin_search("", "", "", "", "æ¨ª", 10)
    print(result)
    
    print("\n=== æµ‹è¯•5: æŸ¥è¯¢3ç¬”ç”»ä¸”åŒ…å«'æ’‡'çš„å­— ===")
    result = process_pinyin_search("3", "", "", "", "æ’‡", 10)
    print(result)
    
    # æ˜¾ç¤ºå¯ç”¨çš„ç¬”ç”»åç§°
    print("\n=== å¯ç”¨çš„ç¬”ç”»åç§° ===")
    stroke_names = searcher.get_available_stroke_names()
    print(f"å…±æœ‰ {len(stroke_names)-1} ç§ç¬”ç”»: {', '.join(stroke_names[1:15])}..." if len(stroke_names) > 15 else f"ç¬”ç”»: {', '.join(stroke_names[1:])}")
