#!/usr/bin/env python3
"""
åŸºäºé¢„è®¡ç®—BERT embeddingsçš„é«˜é€ŸåŒä¹‰è¯æœç´¢å™¨
"""

from typing import List, Tuple, Optional
import re
from bert_embedding_manager import BertEmbeddingManager

class FastBertSynonymSearcher:
    """åŸºäºé¢„è®¡ç®—embeddingsçš„å¿«é€ŸåŒä¹‰è¯æœç´¢å™¨"""
    
    def __init__(self):
        """åˆå§‹åŒ–å¿«é€ŸåŒä¹‰è¯æœç´¢å™¨"""
        self.embedding_manager = BertEmbeddingManager()
        self.initialized = False
        
        print("ğŸ” åˆå§‹åŒ–å¿«é€ŸBERTåŒä¹‰è¯æœç´¢å™¨...")
        
        # å°è¯•åŠ è½½é¢„è®¡ç®—çš„embeddings
        if self.embedding_manager.load_embeddings():
            self.initialized = True
            print("âœ… é¢„è®¡ç®—embeddingsåŠ è½½æˆåŠŸï¼Œè¿›å…¥é«˜é€Ÿæ¨¡å¼")
        else:
            print("âš ï¸ æœªæ‰¾åˆ°é¢„è®¡ç®—embeddingsï¼Œè¯·å…ˆè¿è¡Œ compute_bert_embeddings.py")
            print("ğŸ’¡ æˆ–è€…ä½¿ç”¨å®æ—¶BERTæœåŠ¡æ¨¡å¼")
    
    def _is_chinese(self, text: str) -> bool:
        """æ£€æŸ¥æ–‡æœ¬æ˜¯å¦åŒ…å«ä¸­æ–‡å­—ç¬¦"""
        chinese_pattern = re.compile(r'[\u4e00-\u9fff]+')
        return bool(chinese_pattern.search(text))
    
    def get_synonyms(self, word: str, k: int = 10) -> Tuple[List[str], List[float], str]:
        """è·å–æŒ‡å®šè¯æ±‡çš„ k ä¸ªè¿‘ä¹‰è¯"""
        if not self.initialized:
            return [], [], "âŒ é¢„è®¡ç®—embeddingsæœªåŠ è½½ï¼Œè¯·å…ˆè¿è¡Œ compute_bert_embeddings.py"
        
        if not word or not word.strip():
            return [], [], "âŒ è¯·è¾“å…¥æœ‰æ•ˆçš„è¯æ±‡"
        
        word = word.strip()
        
        # éªŒè¯è¾“å…¥æ˜¯å¦ä¸ºä¸­æ–‡
        if not self._is_chinese(word):
            return [], [], f"âš ï¸ è¾“å…¥'{word}'ä¸æ˜¯ä¸­æ–‡è¯æ±‡ï¼Œå»ºè®®ä½¿ç”¨ä¸­æ–‡"
        
        try:
            # ä½¿ç”¨é¢„è®¡ç®—çš„embeddingsæŸ¥æ‰¾ç›¸ä¼¼è¯
            similar_words = self.embedding_manager.find_similar_words(word, k)
            
            if not similar_words:
                return [], [], f"âŒ è¯æ±‡'{word}'åœ¨é¢„è®¡ç®—è¯åº“ä¸­æœªæ‰¾åˆ°"
            
            # åˆ†ç¦»è¯æ±‡å’Œç›¸ä¼¼åº¦
            synonym_words = [item[0] for item in similar_words]
            similarity_scores = [round(item[1] * 100, 2) for item in similar_words]
            
            status = f"âœ… æ‰¾åˆ° {len(synonym_words)} ä¸ªè¿‘ä¹‰è¯ (é«˜é€ŸBERTæŸ¥è¯¢)"
            return synonym_words, similarity_scores, status
            
        except Exception as e:
            return [], [], f"âŒ æŸ¥è¯¢å‡ºé”™: {str(e)}"
    
    def compare_similarity(self, word1: str, word2: str) -> str:
        """æ¯”è¾ƒä¸¤ä¸ªè¯æ±‡çš„ç›¸ä¼¼åº¦"""
        if not self.initialized:
            return "âŒ é¢„è®¡ç®—embeddingsæœªåŠ è½½ï¼Œè¯·å…ˆè¿è¡Œ compute_bert_embeddings.py"
        
        if not word1 or not word2 or not word1.strip() or not word2.strip():
            return "âŒ è¯·è¾“å…¥ä¸¤ä¸ªæœ‰æ•ˆçš„è¯æ±‡è¿›è¡Œæ¯”è¾ƒ"
        
        word1, word2 = word1.strip(), word2.strip()
        
        # éªŒè¯è¾“å…¥æ˜¯å¦ä¸ºä¸­æ–‡
        if not self._is_chinese(word1) or not self._is_chinese(word2):
            return "âš ï¸ è¾“å…¥çš„è¯æ±‡ä¸æ˜¯ä¸­æ–‡ï¼Œå»ºè®®ä½¿ç”¨ä¸­æ–‡è¯æ±‡"
        
        try:
            # ä½¿ç”¨é¢„è®¡ç®—çš„embeddingsè®¡ç®—ç›¸ä¼¼åº¦
            similarity = self.embedding_manager.compare_words(word1, word2)
            
            if similarity is None:
                missing_words = []
                if self.embedding_manager.get_embedding(word1) is None:
                    missing_words.append(word1)
                if self.embedding_manager.get_embedding(word2) is None:
                    missing_words.append(word2)
                return f"âŒ è¯æ±‡{missing_words}åœ¨é¢„è®¡ç®—è¯åº“ä¸­æœªæ‰¾åˆ°"
            
            # è½¬æ¢ä¸ºç™¾åˆ†æ¯”
            similarity_percent = round(similarity * 100, 2)
            
            # ç”Ÿæˆè¯„ä»·
            if similarity_percent >= 80:
                level = "æé«˜"
            elif similarity_percent >= 60:
                level = "é«˜"
            elif similarity_percent >= 40:
                level = "ä¸­ç­‰"
            elif similarity_percent >= 20:
                level = "è¾ƒä½"
            else:
                level = "å¾ˆä½"
            
            return f"âœ… '{word1}' ä¸ '{word2}' çš„ç›¸ä¼¼åº¦: {similarity_percent}% ({level}) [é«˜é€ŸBERTè®¡ç®—]"
            
        except Exception as e:
            return f"âŒ ç›¸ä¼¼åº¦è®¡ç®—å‡ºé”™: {str(e)}"
    
    def search_words_by_pattern(self, pattern: str, limit: int = 20) -> List[str]:
        """æŒ‰æ¨¡å¼æœç´¢è¯æ±‡"""
        if not self.initialized:
            return []
        
        return self.embedding_manager.search_words(pattern, limit)
    
    def get_embedding_stats(self) -> dict:
        """è·å–embeddingç»Ÿè®¡ä¿¡æ¯"""
        if not self.initialized:
            return {}
        
        return self.embedding_manager.get_stats()

def process_synonym_search(word: str, k: int = 10) -> str:
    """å¤„ç†åŒä¹‰è¯æŸ¥è¯¢çš„ä¸»å‡½æ•°"""
    searcher = FastBertSynonymSearcher()
    
    if not searcher.initialized:
        return f"""âŒ é«˜é€ŸBERTåŒä¹‰è¯åŠŸèƒ½ä¸å¯ç”¨

ğŸ” æŸ¥è¯¢è¯æ±‡: {word}

ğŸ”§ éœ€è¦é¢„è®¡ç®—embeddingsï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

1. ğŸ“Š è¿è¡Œembeddingè®¡ç®—è„šæœ¬ï¼š
   python compute_bert_embeddings.py

2. â³ ç­‰å¾…è®¡ç®—å®Œæˆï¼ˆå¯èƒ½éœ€è¦å‡ å°æ—¶ï¼‰

3. ğŸ”„ é‡æ–°è®¿é—®æ­¤é¡µé¢

ğŸ“š é«˜é€Ÿæ¨¡å¼ä¼˜åŠ¿ï¼š
â€¢ é¢„è®¡ç®—26ä¸‡+ä¸­æ–‡è¯æ±‡çš„BERT embeddings
â€¢ æ¯«ç§’çº§æŸ¥è¯¢å“åº”ï¼Œæ— éœ€ç­‰å¾…å®æ—¶è®¡ç®—
â€¢ æ”¯æŒå¤§è§„æ¨¡è¯åº“çš„è¯­ä¹‰æœç´¢
â€¢ æ›´ç¨³å®šçš„æœåŠ¡ï¼Œä¸ä¾èµ–å®æ—¶BERTæœåŠ¡å™¨

ğŸ’¡ æç¤º: è®¡ç®—è¿‡ç¨‹å¯èƒ½è¾ƒé•¿ï¼Œä½†ä¸€æ¬¡è®¡ç®—æ°¸ä¹…ä½¿ç”¨"""
    
    synonym_words, similarities, status = searcher.get_synonyms(word, k)
    
    if not synonym_words:
        return status
    
    # è·å–ç»Ÿè®¡ä¿¡æ¯
    stats = searcher.get_embedding_stats()
    
    # æ ¼å¼åŒ–è¾“å‡º
    result_lines = [
        f"ğŸ” æŸ¥è¯¢è¯æ±‡: {word}",
        f"ğŸ“Š {status}",
        f"ğŸ“š è¯åº“è§„æ¨¡: {stats.get('total_words', 'N/A')} ä¸ªè¯æ±‡",
        "",
        "ğŸ“ è¿‘ä¹‰è¯åˆ—è¡¨ (é«˜é€ŸBERTæŸ¥è¯¢):",
        "=" * 50
    ]
    
    for i, (syn_word, similarity) in enumerate(zip(synonym_words, similarities), 1):
        result_lines.append(f"{i:2d}. {syn_word:<15} (ç›¸ä¼¼åº¦: {similarity:5.1f}%)")
    
    result_lines.extend([
        "=" * 50,
        f"ğŸ’¡ æç¤º: åŸºäºé¢„è®¡ç®—çš„BERT embeddingsï¼ŒæŸ¥è¯¢é€Ÿåº¦æå¿«",
        f"ğŸ§  è¯åº“: ä¸­æ–‡æ–°åè¯å…¸ + BERTæ·±åº¦å­¦ä¹ æ¨¡å‹",
        f"ğŸ“ˆ å†…å­˜ä½¿ç”¨: {stats.get('memory_usage_mb', 'N/A'):.1f} MB"
    ])
    
    return "\n".join(result_lines)

def process_similarity_comparison(word1: str, word2: str) -> str:
    """å¤„ç†ä¸¤ä¸ªè¯æ±‡ç›¸ä¼¼åº¦æ¯”è¾ƒçš„ä¸»å‡½æ•°"""
    searcher = FastBertSynonymSearcher()
    
    if not searcher.initialized:
        return f"""âŒ é«˜é€ŸBERTç›¸ä¼¼åº¦è®¡ç®—åŠŸèƒ½ä¸å¯ç”¨

ğŸ” æ¯”è¾ƒè¯æ±‡: '{word1}' vs '{word2}'

ğŸ”§ éœ€è¦é¢„è®¡ç®—embeddingsï¼Œè¯·è¿è¡Œï¼š
python compute_bert_embeddings.py

ğŸ“š é«˜é€Ÿæ¨¡å¼è¯´æ˜:
â€¢ åŸºäº26ä¸‡+è¯æ±‡çš„é¢„è®¡ç®—BERT embeddings
â€¢ æ¯«ç§’çº§ç›¸ä¼¼åº¦è®¡ç®—
â€¢ æ— éœ€ç­‰å¾…å®æ—¶BERTæœåŠ¡å“åº”
â€¢ æ”¯æŒç¦»çº¿ä½¿ç”¨

ğŸ’¡ ç›¸ä¼¼åº¦ç­‰çº§:
â€¢ 80%ä»¥ä¸Š: æé«˜ç›¸ä¼¼åº¦ï¼ˆè¿‘ä¹‰è¯ï¼‰
â€¢ 60-80%: é«˜ç›¸ä¼¼åº¦ï¼ˆç›¸å…³è¯æ±‡ï¼‰  
â€¢ 40-60%: ä¸­ç­‰ç›¸ä¼¼åº¦ï¼ˆä¸»é¢˜ç›¸å…³ï¼‰
â€¢ 20-40%: è¾ƒä½ç›¸ä¼¼åº¦ï¼ˆæœ‰ä¸€å®šå…³è”ï¼‰
â€¢ 20%ä»¥ä¸‹: å¾ˆä½ç›¸ä¼¼åº¦ï¼ˆåŸºæœ¬æ— å…³ï¼‰"""
    
    result = searcher.compare_similarity(word1, word2)
    stats = searcher.get_embedding_stats()
    
    # æ·»åŠ é¢å¤–ä¿¡æ¯
    result_lines = [
        "ğŸ” è¯æ±‡ç›¸ä¼¼åº¦æ¯”è¾ƒ (é«˜é€ŸBERT)",
        "=" * 35,
        result,
        "",
        "ğŸ§  è®¡ç®—æ–¹æ³•: é¢„è®¡ç®—BERT embeddings + ä½™å¼¦ç›¸ä¼¼åº¦",
        f"ğŸ“š è¯åº“è§„æ¨¡: {stats.get('total_words', 'N/A')} ä¸ªè¯æ±‡",
        f"ğŸ“ˆ å‘é‡ç»´åº¦: {stats.get('vector_dimension', 'N/A')}",
        "",
        "ğŸ’¡ è¯´æ˜:",
        "â€¢ åŸºäºé¢„è®¡ç®—embeddingsï¼ŒæŸ¥è¯¢é€Ÿåº¦æå¿«",
        "â€¢ ä½¿ç”¨å®Œæ•´çš„ä¸­æ–‡æ–°åè¯å…¸è¯åº“",
        "â€¢ BERTæ·±åº¦å­¦ä¹ æ¨¡å‹æä¾›å‡†ç¡®çš„è¯­ä¹‰ç†è§£"
    ]
    
    return "\n".join(result_lines)

if __name__ == "__main__":
    # æµ‹è¯•å¿«é€ŸBERTåŒä¹‰è¯åŠŸèƒ½
    print("ğŸ§ª æµ‹è¯•é«˜é€ŸBERTåŒä¹‰è¯åŠŸèƒ½...")
    
    test_words = ["é«˜å…´", "ç¾ä¸½", "å­¦ä¹ "]
    for word in test_words:
        print(f"\næµ‹è¯•è¯æ±‡: {word}")
        result = process_synonym_search(word, 5)
        print(result)
    
    print("\næµ‹è¯•ç›¸ä¼¼åº¦æ¯”è¾ƒ...")
    result = process_similarity_comparison("é«˜å…´", "å¿«ä¹")
    print(result)
